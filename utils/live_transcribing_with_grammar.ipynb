{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import queue\n",
    "import sounddevice as sd\n",
    "import vosk\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=10 max-active=3000 lattice-beam=2\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from ../vosk-model-small-en-us-0.15/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:282) Loading HCL and G from ../vosk-model-small-en-us-0.15/graph/HCLr.fst ../vosk-model-small-en-us-0.15/graph/Gr.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:308) Loading winfo ../vosk-model-small-en-us-0.15/graph/phones/word_boundary.int\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define your model path here\n",
    "MODEL_PATH = \"../vosk-model-small-en-us-0.15\"\n",
    "\n",
    "# Define keywords you want to detect\n",
    "KEYWORDS = [\"hello\", \"world\", \"python\", \"game\"]\n",
    "\n",
    "# Set up Vosk model and recognizer\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(f\"Model path {MODEL_PATH} does not exist. Please check the path.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "model = vosk.Model(MODEL_PATH)\n",
    "recognizer = vosk.KaldiRecognizer(model, 16000)\n",
    "recognizer.SetWords(True)  # Enable word detection\n",
    "\n",
    "# Set up audio stream\n",
    "q = queue.Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:UpdateGrammarFst():recognizer.cc:287) [\"one\", \"two\", \"three\", \"[unk]\"]\n",
      "LOG (VoskAPI:Estimate():language_model.cc:142) Estimating language model with ngram-order=2, discount=0.5\n",
      "LOG (VoskAPI:OutputToFst():language_model.cc:209) Created language model with 5 states and 8 arcs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start speaking...\n",
      "Partial result: \n",
      "Partial result: \n",
      "Partial result: \n",
      "Partial result: one\n",
      "Partial result: one two three\n",
      "Partial result: one two three\n",
      "one 1.62 1.89\n",
      "two 1.89 2.1\n",
      "three 2.1 2.49\n",
      "Partial result: one\n",
      "Partial result: one\n",
      "Partial result: one\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(status, file=sys.stderr)\n",
    "    q.put(bytes(indata))\n",
    "\n",
    "poem = \"Once upon a midnight dreary, while I pondered, weak and weary, Over many a quaint and curious volume of forgotten lore— While I nodded, nearly napping, suddenly there came a tapping, As of some one gently rapping, rapping at my chamber door. “’Tis some visitor,” I muttered, “tapping at my chamber door— Only this and nothing more.”\"\n",
    "poem = \"is there balm in gilead, tell me, tell me, i implore!\"\n",
    "poem = \"one two three\"\n",
    "stripped_poem = ''.join(e for e in poem if e.isalnum() or e.isspace())\n",
    "poem_words = stripped_poem.split()\n",
    "poem_words = [word.lower() for word in poem_words]\n",
    "poem_words += [\"[unk]\"]  # Add [unk] token for unknown words\n",
    "grammar_str = json.dumps(poem_words)\n",
    "recognizer.SetGrammar(grammar_str)\n",
    "\n",
    "\n",
    "try:\n",
    "    with sd.RawInputStream(samplerate=16000, blocksize=8000, dtype='int16',\n",
    "                           channels=1, callback=callback):\n",
    "        print(\"Start speaking...\")\n",
    "\n",
    "        while True:\n",
    "            data = q.get()\n",
    "            if recognizer.AcceptWaveform(data):\n",
    "                result = recognizer.Result()\n",
    "                result_dict = json.loads(result)\n",
    "                heard_words = result_dict.get(\"result\", [])\n",
    "                for w in heard_words:\n",
    "                    print(w['word'], w['start'], w['end'])\n",
    "            else:\n",
    "                partial_result = recognizer.PartialResult()\n",
    "                partial_dict = json.loads(partial_result)\n",
    "                print(\"Partial result:\", partial_dict.get(\"partial\"))\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nDone\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use vosk and a known grammar to perform forced alignment\n",
    "\n",
    "grammar = \"testing one two three\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
